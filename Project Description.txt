This work is conducted by members of group 15:

Nima Taherifard, #300094057
Johan Fernandes, #300114784 

Our submission consist of the NLP Project- Visual Question and Answering report
and the github link: https://github.com/ferna11i/NLP_VQA


For this project we tried to understand the inner workings of the state-of-the-art VQA models.
In our research we studied the components of 4 models. Due to lack of a GPU we could not implement
these models on the complete dataset. 
Thus we did our best to explain the important components of these models and what makes them
better than the rest. Thus our github repo is simply a collection of steps on how to use the models
whose code base was available.

The attached report will give you a brief understanding of each of these models. The top 3 models that
are described in the document have actually secured the top 3 spot in the VQA 2019 challenge.

The VQA 2020 challenge is about to end and we hope to learn and add more to this repo and our report
when the results are announced.